
\section{Methods and Implementations}
In order to compare our method to those in the literature we implemented our algorithm in \verb+R+ and made it available on \href{https://github.com/gjhunt/deconvolution}{github}. Our implementation currently works only for Affymetrix GeneChips and so the comparisons in this chapter are only on that type of data. The implementation follows exactly that described in Chapter \ref{chap:Method}. For the analysis in this chapter we ran our algorithm on $\log_2$ probe-level measurements using 1000 marker probes (oligos) to distinguish among the cell types. For comparison we looked at six other deconvolution algorithms available as part of the \verb+CellMix+ package. Apart from our own partial deconvolution algorithm we looked at two partial deconvolution algorithms which we call, following \citeauthor{Gaujoux2013}, \verb+lsfit+ (Least Squares fit) and \verb+qprog+ (Quadratic Programming). The algorithm \verb+lsfit+ is an implementation by \citeauthor{Gaujoux2013} of the method presented in \cite{Abbas2009} which fits the mixing proportions using a heuristic iterative regression algorithm. The algorithm \verb+qprog+ is an implementation by \citeauthor{Gaujoux2013} of the method presented in \cite{Gong2011}. This partial deconvolution algorithm fits the mixing proportions using a quadratic programming method explicitly incorporating constraints on the mixing proportions. We also compared our algorithm to several complete deconvolution methods. We compared to the algorithm \verb+DSA+ put forth in \cite{Zhong2013} and two versions of the full deconvolution algorithm put forth by \cite{Gaujoux2012}. These latter deconvolution algorithms are referred to as \verb+ssKL+ and \verb+ssFrobenius+. Since our algorithm is most comparable to those methods in the literature that work at the linear (non-$\log$) level we ran all of these algorithms at the linear level. However all algorithms in the literature work with probe sets and not probes. Thus while our analysis was working with individual probes on the Affymetrix microarrays the other algorithms worked with data summarized into probe-set level measurements. Our algorithm worked with 1000 marker probes and so for the other algorithms we had to provide commensurate marker probesets. Since the markers chosen have a large impact on the efficacy of the deconvolution algorithm we wanted to change as little as possible for the markers from one algorithm to another. Thus we designated probesets as markers for cell types as follows. A probeset was considered to be a marker for cell type $k$ if it had at least one probe that we considered to be a marker for cell type $k$ and if among all of its probes considered to be markers for some cell type the cell type most frequently marked was type $k$. To compare our algorithm with those in the literature we ran all six algorithms on two data sets. 

\section{The Rat Data Set}

The first data set we looked at was a data set of mixtures of rat cells from \cite{Shen-Orr2010}. The data set is available from GEO with accession key \href{https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE19830}{GSE19830}. The data set was created by running a Affymetrix Rat Genome 230 2.0 DNA microarray on known mixtures of rat brain, liver and lung biospecimens. The mixtures were created at the cRNA homogenate level. There were 14 different mixing proportions used to make the data with three technical replicates each for a total of 42 DNA microarrays. Data from three microarrays of pure samples (one each of brain, liver and lung) were used to choose the marker genes. These three arrays were then excluded from the analysis further as they were effectively used to train the algorithms. For the remaining DNA microarray data we ran each of our six algorithm and predicted the cell type mixing proportions using the selected marker genes. Since the true mixing proportions were known we were able to compare them to predicted mixing proportions for each algorithm. In Table \ref{tab:rat1} we show quantiles of the absolute value of the error of the mixing proportions predicted by the various algorithms.


<<table1,cache=FALSE,warning=FALSE,echo=FALSE,error=FALSE,message=FALSE,results='asis'>>=
library('xtable')
source('./R/Analysis_script.R',chdir=TRUE)
sel = sel=c(TRUE,FALSE,TRUE,FALSE,FALSE,FALSE)
t = aplot(19830,'summ',sel)
print(xtable(t,caption="Quantiles of the absolute error of predicted mixing proportions.",
             label="tab:rat1"
             ),include.rownames=FALSE)
@ 

We can see from this table that the maximum error for our algorithm is a little less than 6\%. Furthermore our algorithm has a smaller maximum and median absolute error than all other algorithms. In Figure \ref{fig:ratbox} we display box-plots of all the errors of all six algorithms. 

\begin{figure}[ht]
  \centering
<<plot2,cache=FALSE,warning=FALSE,echo=FALSE,error=FALSE,message=FALSE,fig.height=4,fig.width=7>>=
source('./R/Analysis_script.R',chdir=TRUE)
sel = sel=c(TRUE,FALSE,TRUE,FALSE,FALSE,FALSE)
aplot(19830,'err_boxplot',sel)
@ 
\caption{Error of predicted mixing proportions.}
\label{fig:ratbox}
\end{figure}

We see largely the same story where our algorithm has a much smaller error across the board compared to all other algorithms. It appears that the \verb+lsfit+ algorithm does second best in terms of error and so we plot the individual predictions of our algorithm and the \verb+lsfit+ algorithm against each other in Figure \ref{fig:rat}.

\begin{figure}[ht]
  \centering
<<plot1,cache=FALSE,warning=FALSE,echo=FALSE,error=FALSE,message=FALSE,fig.height=5,fig.width=7>>=
source('./R/Analysis_script.R',chdir=TRUE)
sel = sel=c(TRUE,FALSE,TRUE,FALSE,FALSE,FALSE)
aplot(19830,'diag',sel)
@ 
\caption{Predicted proportions against true proportions for ours and the lsfit algorithm.}
\label{fig:rat}
\end{figure}

In this figure we plot the estimated proportions for each of the two algorithms against the actual known mixing proportions. Points on the orange diagonal 45 degree line are those where the estimated proportion exactly equals the true proportion. Thus deviations from this orange line are errors. While the \verb+lsfit+ algorithm does quite well we can see that our deconvolution algorithm does better. It follows the orange line better whereas the \verb+lsfit+ algorithm seems to have a large problem overestimating for truly small proportions and underestimating truly large proportions.   

\section{The Blood Data set}

While the previous data set showed our algorithm in a very good light we would also like to look at a data set where our algorithm does not do as well. For this we look at data set comprised of mixtures of white blood cell types. This data set comes from \cite{Abbas2009}. The data set is available from GEO with accession key \href{https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE11058}{GSE11058}. The data set is a mixture of lines of human immune and memory T cells. Specifically the data set was created by running HG-U133 Plus 2 Affymetrix Human Genome DNA microarrays on mixtures of Jurkat, IM-9, Raji and THP-1 cell lines. Three technical replicates of various mixtures of the cells were analyzed with the DNA microarrays. We used four pure arrays (one for each immune cell type) to select the 1000 marker probes and subsequently marker probesets. Since these arrays were used to train the algorithms they are excluded from the following analyses. We then ran each of the six deconvolution algorithms on the DNA microarray data and estimated the mixing proportions. We display quantiles of the absolute value of the errors of the mixing proportions in Table \ref{tab:blood}.

<<table2,cache=FALSE,warning=FALSE,echo=FALSE,error=FALSE,message=FALSE,results='asis'>>=
library('xtable')
source('./R/Analysis_script.R',chdir=TRUE)
sel = sel=c(TRUE,FALSE,TRUE,FALSE,FALSE,FALSE)
t = aplot(11058,'summ',sel)
print(xtable(t,label="tab:blood",caption="Quantiles of the absolute error of predicted mixing proportions."),include.rownames=FALSE)
@ 

Here we can see that our algorithm does well but not the best. In terms of absolute error of mixing proportions our algorithm has the second lowest maximum behind the \verb+lsfit+ algorithm and third lowest median behind both the \verb+lsfit+ and \verb+qprog+ algorithms. We display box-plots of the errors in Figure \ref{fig:bloodbox}.

\begin{figure}[ht]
  \centering
<<plot4,cache=FALSE,warning=FALSE,echo=FALSE,error=FALSE,message=FALSE,fig.height=4,fig.width=7>>=
source('./R/Analysis_script.R',chdir=TRUE)
sel = sel=c(TRUE,FALSE,TRUE,FALSE,FALSE,FALSE)
aplot(11058,'err_boxplot',sel)
@ 
\caption{Error of predicted mixing proportions.}
\label{fig:bloodbox}
\end{figure}

From this Figure we can see that the \verb+lsfit+ and \verb+qprog+ algorithms seem to perform the best and the other algorithms, including ours, seems to be about on par. Our algorithm seems to have a small maximum and median for errors but a relatively large spread.  Notably our algorithm doesn't seem to over-predict nor under-predict more often than the other. It seems to have a fairly symmetrical distribution of errors. The three full deconvolution methods tend to have a positive prediction error meaning that they tend to predict a mixing proportion higher than the truth. This is not too surprising if we look at Figure \ref{fig:blood} as we can see that most of the true mixing proportions are quite small. In Figure \ref{fig:blood} we plot the estimated proportions against the true proportions. We do this both for our algorithm and the algorithm that performs the best, \verb+lsfit+. We can see that while it's true that \verb+lsfit+ does well our algorithm is not far behind. 

\begin{figure}[ht]
  \centering
<<plot3,cache=FALSE,warning=FALSE,echo=FALSE,error=FALSE,message=FALSE,fig.height=5,fig.width=7>>=
source('./R/Analysis_script.R',chdir=TRUE)
sel = sel=c(TRUE,FALSE,TRUE,FALSE,FALSE,FALSE)
aplot(11058,'diag',sel)
@ 
\caption{Predicted proportions against true proportions for ours and the lsfit algorithm.}
\label{fig:blood}
\end{figure}







